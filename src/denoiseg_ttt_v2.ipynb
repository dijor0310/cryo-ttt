{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from copy import deepcopy\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from utils.utils import set_seed\n",
    "from utils.subtomos import reassemble_subtomograms, reassemble_subtomograms_v2\n",
    "from utils.connected_components import connected_components\n",
    "from torchmetrics.classification import BinaryConfusionMatrix\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as FT\n",
    "from datasets import build_dataset\n",
    "# from models import build_model\n",
    "from models.denoiseg import Denoiseg\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 2\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg = OmegaConf.merge(cfg, cfg.method)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "criterion = DiceLoss(sigmoid=True)\n",
    "scoring_fn = DiceMetric(reduction='mean')\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss(reduction='none')\n",
    "# mse_loss = nn.L1Loss(reduction='none')\n",
    "device = torch.device(\"cuda:3\")\n",
    "device_1 = torch.device(\"cuda:1\")\n",
    "bcm = BinaryConfusionMatrix().to(device)\n",
    "\n",
    "dataset = build_dataset(cfg, test=True)\n",
    "\n",
    "test_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 2, 2], generator=torch.Generator().manual_seed(cfg.seed))\n",
    "print(len(test_dataset), len(test_val_dataset))\n",
    "# test_dataset = dataset\n",
    "# test_val_dataset = build_dataset(cfg, val=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    # num_workers=cfg.load_num_workers,\n",
    "    num_workers=0,\n",
    "    batch_size=5,\n",
    "    shuffle=True,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")            \n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_dataset,\n",
    "    num_workers=cfg.load_num_workers,\n",
    "    batch_size=2,\n",
    "    persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=cfg.load_num_workers,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_entire_gt = mrcfile.read(cfg.test_entire_gt)\n",
    "test_entire_gt = torch.Tensor(test_entire_gt)[None, None, ...]\n",
    "test_membrain_pred = mrcfile.read(cfg.test_membrain_pred)\n",
    "test_membrain_pred = torch.Tensor(test_membrain_pred)[None, None, ...]\n",
    "# print(test_entire_gt.shape)\n",
    "\n",
    "model = Denoiseg.load_from_checkpoint(cfg.ckpt_path, map_location=device, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([3, 1, 256, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"64\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"64\"\n",
    "\n",
    "for batch in test_loader:\n",
    "    print(batch[\"mask\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([5, 1, 256, 256, 256])\n",
      "torch.Size([3, 1, 256, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "del os.environ[\"OMP_NUM_THREADS\"]\n",
    "del os.environ[\"MKL_NUM_THREADS\"]\n",
    "for batch in test_loader:\n",
    "    print(batch[\"mask\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(x_hat, x, mask):\n",
    "    loss = mse_loss(x_hat, x) * mask\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "def dice_from_conf_matrix(conf_matrix):\n",
    "    return 2 * conf_matrix[1, 1] / (2 * conf_matrix[1, 1] + conf_matrix[0, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm\n",
    "\n",
    "def process_id(id):\n",
    "    id = id.split(\"_\")[-1]\n",
    "    id = id[1:-1].split(\" \")\n",
    "    id = [int(elem) for elem in id]\n",
    "    return id\n",
    "\n",
    "def normalize_image(image, max_intensity):\n",
    "\n",
    "    return image * 255.0 / max_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_test_loop(test_test_loader, model, run, epoch):\n",
    "    # Test\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = []\n",
    "    ids = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(test_test_loader):\n",
    "            x_unmasked = batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            y_hat, x_hat = model.model(x_unmasked)\n",
    "\n",
    "            dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().item()\n",
    "            conf_matrix += bcm(y_hat.sigmoid(), y_out).detach().cpu()\n",
    "            \n",
    "            slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "\n",
    "            # id = id[0].replace(\" \", \"_\")\n",
    "            preds.append(y_hat.squeeze().detach().cpu().numpy())\n",
    "            ids.append(process_id(id[0]))\n",
    "            run.log({\n",
    "                f\"train/{i}/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "                f\"train/{i}/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "                f\"train/{i}/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                f\"train/{i}/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                f\"train/{i}/dice\": dice,\n",
    "                # f\"train/{i}/dice_loss\": dice_loss,\n",
    "                \"epoch\": epoch,\n",
    "            })\n",
    "        \n",
    "        reassembled_pred = reassemble_subtomograms_v2(preds, ids, test_entire_gt.shape[2:], 256, 12)\n",
    "        reassembled_pred = (torch.Tensor(reassembled_pred).sigmoid() > 0.5).to(torch.uint8)[None, None, ...]\n",
    "        # postprocessed_pred = torch.Tensor(connected_components(reassembled_pred.squeeze().numpy(), 50)).to(torch.bool).to(torch.uint8)\n",
    "        # print(test_entire_gt[0].sum(dim=1).dim())\n",
    "        max_intensity = np.max(test_entire_gt[0].sum(dim=1).numpy())\n",
    "        run.log({\n",
    "            \"train/macro_dice\": dice_from_conf_matrix(conf_matrix),\n",
    "            \"train/rsm_macro_dice\": scoring_fn(reassembled_pred, test_entire_gt).item(),\n",
    "            \"membrain/macro_dice\": scoring_fn(test_membrain_pred[:, :, :test_entire_gt.shape[2], :test_entire_gt.shape[3], :test_entire_gt.shape[4]], test_entire_gt).item(),\n",
    "            \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(normalize_image(test_entire_gt[0, :].sum(dim=1), max_intensity).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_image(reassembled_pred[0].sum(dim=1), max_intensity).to(torch.uint8), mode=\"L\")),\n",
    "            \"membrain/seg_overall\": wandb.Image(FT.to_pil_image(normalize_image(test_membrain_pred[0, :].sum(dim=1), max_intensity).to(torch.uint8), mode=\"L\")),\n",
    "            # \"train/seg_overall_postprocessed\": wandb.Image(FT.to_pil_image(postprocessed_pred[None, ...].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "def ttt_one_tomo(test_loader, model, n_epochs, lr, momentum, test_val_loader=None, test_test_loader=None):\n",
    "    \n",
    "    random_uuid = uuid.uuid4()\n",
    "    random_string = str(random_uuid).replace(\"-\", \"\")[:5]\n",
    "\n",
    "    run = wandb.init(project=\"cryo-ttt-ttt\", name=f\"{cfg.exp_name}-lr-{lr:.2E}-{random_string}\")\n",
    "    print(cfg)\n",
    "    macro_test_loop(test_test_loader, model, run, epoch=0)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum=momentum, lr=lr)    \n",
    "    \n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        for batch in test_loader:\n",
    "            # -------------\n",
    "            # Train step\n",
    "            model.train()\n",
    "\n",
    "            x_masked, x_unmasked = batch[\"image\"].to(device), batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # y_hat, x_hat = model.model(x_masked)\n",
    "            # ### Normalize\n",
    "            # x_masked, mean, std = model.normalize(x_masked)\n",
    "            # ###\n",
    "\n",
    "            y_hat, x_hat = model.model(x_masked)\n",
    "\n",
    "            # ### Denormalize\n",
    "            # x_hat = model.denormalize(x_hat, mean, std)\n",
    "            # ###\n",
    "\n",
    "\n",
    "            loss = masked_mse_loss(x_hat, x_unmasked, mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_grad_norm = get_grad_norm(model.model)\n",
    "            dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().mean().item()\n",
    "\n",
    "            val_losses = []\n",
    "            for batch_val in test_val_loader:\n",
    "                # --------------\n",
    "                # Validation step\n",
    "                model.eval()\n",
    "\n",
    "                x_masked_val, x_unmasked_val = batch_val[\"image\"].to(device), batch_val[\"unmasked_image\"].to(device)\n",
    "                y_out_val, id_val = batch_val[\"label\"].to(device), batch_val[\"id\"]\n",
    "                mask_val = batch_val[\"mask\"].to(device)\n",
    "\n",
    "                _, x_hat_val = model.model(x_masked_val)\n",
    "\n",
    "                val_mse_loss = masked_mse_loss(x_hat_val, x_unmasked_val, mask_val)\n",
    "                val_losses.append(val_mse_loss.item())\n",
    "\n",
    "                slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "            \n",
    "            # Log results after step i\n",
    "            run.log({\n",
    "                \"train/mse_loss\": loss.item(),\n",
    "                \"train/dice_loss\": dice_loss,\n",
    "                \"train/dice\": dice,\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": step,\n",
    "                # \"train/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "                # \"train/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "                # \"train/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                \"train/mask\": wandb.Image(FT.to_pil_image((mask[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                \"val/mse_loss\": np.array(val_losses).mean(),\n",
    "                # \"train/grad_norm\": train_grad_norm,\n",
    "                # \"train/intensity_var\": x_hat.var(),\n",
    "                # \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(y_out[0, :].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :] > 0.5).sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            })\n",
    "\n",
    "            step += 1\n",
    "        macro_test_loop(test_test_loader, model, run, epoch=epoch)\n",
    "        \n",
    "    run.finish()\n",
    "    # return y_hat, val_losses, val_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdijor0310\u001b[0m (\u001b[33mcryo-diyor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cryo/cryo-ttt/src/wandb/run-20250305_145947-ckwwj13b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/ckwwj13b' target=\"_blank\">def-vpp-001-norm-shuffle-lr-5.00E-04-dfda2</a></strong> to <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/ckwwj13b' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/ckwwj13b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'def-vpp-001-norm-shuffle', 'ckpt_path': '/workspaces/cryo/cryo-ttt/src/ttt_ckpt/denoiseg-gn-def-norm_data-shuffle-67fe4/epoch=893-val/dice_loss=0.44.ckpt', 'seed': 42, 'debug': False, 'devices': [2], 'profiler': 'simple', 'strategy': 'auto', 'shuffle': True, 'load_num_workers': 32, 'pin_memory': False, 'persistent_workers': True, 'accumulate_grad_batches': 2, 'gradient_clip_val': None, 'log_every_n_steps': 1, 'method': {'model_name': 'denoiseg', 'train_batch_size': 8, 'eval_batch_size': 1, 'test_batch_size': 1, 'dataset': 'denoiseg', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'learning_rate': 0.0005, 'decay_milestones': [], 'decay_gamma': 1.0, 'max_epochs': 1000, 'grad_clip_norm': None, 'train_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/def_train', 'val_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/def_val', 'test_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/vpp_train/001', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0001_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/membrain_out_no_aug/TS_0001_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc', 'normalize_data': False}, 'model_name': 'denoiseg', 'train_batch_size': 8, 'eval_batch_size': 1, 'test_batch_size': 1, 'dataset': 'denoiseg', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'learning_rate': 0.0005, 'decay_milestones': [], 'decay_gamma': 1.0, 'max_epochs': 1000, 'grad_clip_norm': None, 'train_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/def_train', 'val_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/def_val', 'test_data_root_dir': '/media/ssd3/diyor/30-01-deepict-norm-256/work/training_data/vpp_train/001', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0001_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/membrain_out_no_aug/TS_0001_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc', 'normalize_data': False}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mttt_one_tomo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_val_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_test_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_test_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 55\u001b[0m, in \u001b[0;36mttt_one_tomo\u001b[0;34m(test_loader, model, n_epochs, lr, momentum, test_val_loader, test_test_loader)\u001b[0m\n\u001b[1;32m     53\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcryo-ttt-ttt\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-lr-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2E\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mmacro_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     58\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), momentum\u001b[38;5;241m=\u001b[39mmomentum, lr\u001b[38;5;241m=\u001b[39mlr)    \n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mmacro_test_loop\u001b[0;34m(test_test_loader, model, run, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m x_unmasked \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munmasked_image\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m y_out, \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m y_hat, x_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_unmasked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m dice_loss \u001b[38;5;241m=\u001b[39m criterion(y_hat, y_out)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     14\u001b[0m dice \u001b[38;5;241m=\u001b[39m scoring_fn((y_hat\u001b[38;5;241m.\u001b[39msigmoid() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint(), y_out)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspaces/cryo/cryo-ttt/src/models/denoiseg.py:473\u001b[0m, in \u001b[0;36mUNet3D.forward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    471\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m--> 473\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     encoder_out\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    475\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoolers[level](x)\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "ttt_one_tomo(test_loader, model, 30, 0.0005, 0.9, test_val_loader=test_val_loader, test_test_loader=test_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([-0.0078,  0.0039,  0.0066,  0.0021, -0.0166])\n",
      "var: tensor([1.0411, 1.0905, 1.0543, 1.0585, 0.8818])\n",
      "mean: tensor([ 0.0134, -0.0009, -0.0142,  0.0024,  0.0047])\n",
      "var: tensor([1.1368, 1.0887, 1.0626, 1.1120, 1.0318])\n",
      "mean: tensor([ 0.0020,  0.0087,  0.0012,  0.0035, -0.0145])\n",
      "var: tensor([1.0689, 0.9181, 0.8958, 1.1233, 0.8515])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    x_unmasked = batch[\"unmasked_image\"]\n",
    "\n",
    "    print(f\"mean: {x_unmasked.mean(dim=(-1, -2, -3, -4))}\")\n",
    "    print(f\"var: {x_unmasked.var(dim=(-1, -2, -3, -4))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
