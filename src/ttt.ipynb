{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from copy import deepcopy\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(gt, pred, pred_refined, id):\n",
    "\n",
    "    batch_size = gt.size(0)\n",
    "    for sample in range(batch_size):\n",
    "        # gt = gt.sum(dim=0)\n",
    "        # pred = pred.sum(dim=0)\n",
    "        # pred_refined = pred.sum(dim=0)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Display each image with its corresponding title\n",
    "        images = [gt, pred, pred_refined]\n",
    "        titles = [\"gt\", \"pred\", \"pred after ttt\"]\n",
    "\n",
    "        for ax, img, title in zip(axes, images, titles):\n",
    "            ax.imshow(img[sample, 0].cpu().detach().sum(dim=0))\n",
    "            ax.set_title(title)\n",
    "            ax.axis(\"off\")  # Hide axes for better visual appearance\n",
    "\n",
    "        # Adjust layout and save the figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(\"./plots\") / f\"{id[sample]}.png\", bbox_inches='tight')\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss(sigmoid=True)\n",
    "scoring_fn = DiceMetric()\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:2\")\n",
    "device_1 = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt_one_batch(batch, model, model_ttt, optimizer, n_steps):\n",
    "    model_ttt.load_state_dict(model.state_dict())\n",
    "    model_ttt.train()\n",
    "    for step in range(n_steps):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat_0 = model_ttt.model(torch.Tensor(batch[\"image\"]).to(device), y=None)\n",
    "        y_hat_1 = model.model(torch.Tensor(batch[\"image\"]).to(device), y=y_hat_0)\n",
    "\n",
    "        # values = torch.Tensor([1])\n",
    "        loss = criterion(y_hat_0, (nn.functional.sigmoid(y_hat_1) > 0.5).int())\n",
    "        # loss = cross_entropy(y_hat_0, y_hat_1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"Step {step}: {loss:.2f}\")\n",
    "\n",
    "    return y_hat_0, y_hat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttt(model, test_loader, n_steps, lr):\n",
    "\n",
    "    # model_ttt = deepcopy(model)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # model_ttt.eval()\n",
    "    # model_ttt.to(device)\n",
    "\n",
    "    # optimizer = torch.optim.Adam(model_ttt.parameters(), lr=lr)\n",
    "    test_loss_0, test_loss_1 = 0., 0.\n",
    "\n",
    "    score_0, score_1 = [], []\n",
    "    score_0_refined, score_1_refined = [], []\n",
    "\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        x, y = torch.Tensor(batch[\"image\"]), torch.Tensor(batch[\"label\"])\n",
    "        print(batch[\"id\"])\n",
    "\n",
    "        model_ttt = deepcopy(model)\n",
    "        model_ttt.eval()\n",
    "        model_ttt.to(device)\n",
    "        optimizer = torch.optim.SGD(model_ttt.parameters(), lr=lr, momentum=0.9)\n",
    "        # optimizer = torch.optim.Adam(model_ttt.parameters(), lr=lr)\n",
    "\n",
    "        y_hat_0 = model_ttt.model(torch.Tensor(batch[\"image\"]).to(device), y=None)\n",
    "        y_hat_1 = model.model(torch.Tensor(batch[\"image\"]).to(device), y=y_hat_0.to(device))\n",
    "        \n",
    "        score_0.append((1 - criterion(y_hat_0, y.to(device))).detach().item())\n",
    "        score_1.append((1 - criterion(y_hat_1.to(device), y.to(device))).detach().item())\n",
    "        # print(f\"y_hat_0: {1 - criterion(y_hat_0, y.to(device)):.2f}; y_hat_1: {1 - criterion(y_hat_1, y.to(device)):.2f}\")\n",
    "\n",
    "        y_hat_0_refined, y_hat_1_refined = ttt_one_batch(batch, model, model_ttt, optimizer, n_steps)\n",
    "\n",
    "        # # print(f\"RES y_hat_0: {1 - criterion(y_hat_0, y.to(device)):.2f}; y_hat_1: {1 - criterion(y_hat_1, y.to(device)):.2f}\")\n",
    "        model_ttt.eval()\n",
    "        score_0_refined.append((1 - criterion(y_hat_0_refined, y.to(device))).detach().item())\n",
    "        score_1_refined.append((1 - criterion(y_hat_1_refined.to(device), y.to(device))).detach().item())\n",
    "\n",
    "        plot(y, y_hat_0, y_hat_0_refined, batch[\"id\"])\n",
    "\n",
    "    print(f\"score_0: {sum(score_0) / len(score_0)}, std: {np.array(score_0).std()}\")\n",
    "    print(f\"score_1: {sum(score_1) / len(score_1)}, std: {np.array(score_1).std()}\")\n",
    "    print(f\"score_0_refined: {sum(score_0_refined) / len(score_0_refined)}, std: {np.array(score_0_refined).std()}\")\n",
    "    print(f\"score_1_refined: {sum(score_1_refined) / len(score_1_refined)}, std: {np.array(score_1_refined).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp_name', 'ckpt_path', 'seed', 'debug', 'devices', 'load_num_workers', 'log_every_n_steps', 'method', 'model_name', 'train_batch_size', 'eval_batch_size', 'test_batch_size', 'dataset', 'depth', 'initial_features', 'encoder_dropout', 'decoder_dropout', 'BN', 'elu', 'learning_rate', 'base_lr', 'max_lr', 'step_size', 'decay_milestones', 'decay_gamma', 'weight_decay', 'max_epochs', 'grad_clip_norm', 'train_data_root_dir', 'val_data_root_dir', 'test_data_root_dir', 'normalize_data']\n"
     ]
    }
   ],
   "source": [
    "from datasets import build_dataset\n",
    "from models import build_model\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"configs/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg = OmegaConf.merge(cfg, cfg.method)\n",
    "\n",
    "# model = build_model(cfg)\n",
    "test_loader = torch.utils.data.DataLoader(build_dataset(cfg, test=True), num_workers=16, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.deepict_unet3d_ttt import UNet3D_Lightning_ITTT\n",
    "\n",
    "model = UNet3D_Lightning_ITTT.load_from_checkpoint(cfg.ckpt_path, map_location=device, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['034_subtomo_[128 128 360]']\n",
      "['034_subtomo_[128 128 592]']\n",
      "['034_subtomo_[128 128 824]']\n",
      "['034_subtomo_[128 360 128]']\n",
      "['034_subtomo_[128 360 360]']\n",
      "['034_subtomo_[128 360 592]']\n",
      "['034_subtomo_[128 360 824]']\n",
      "['034_subtomo_[128 592 128]']\n",
      "['034_subtomo_[128 592 360]']\n",
      "['034_subtomo_[128 592 592]']\n",
      "['034_subtomo_[128 592 824]']\n",
      "['034_subtomo_[128 824 128]']\n",
      "['034_subtomo_[128 824 360]']\n",
      "['034_subtomo_[128 824 592]']\n",
      "['034_subtomo_[128 824 824]']\n",
      "['030_subtomo_[128 128 592]']\n",
      "['030_subtomo_[128 128 824]']\n",
      "['030_subtomo_[128 360 360]']\n",
      "['030_subtomo_[128 360 592]']\n",
      "['030_subtomo_[128 360 824]']\n",
      "['030_subtomo_[128 592 128]']\n",
      "['030_subtomo_[128 592 360]']\n",
      "['030_subtomo_[128 592 592]']\n",
      "['030_subtomo_[128 592 824]']\n",
      "['030_subtomo_[128 824 128]']\n",
      "['030_subtomo_[128 824 360]']\n",
      "['030_subtomo_[128 824 592]']\n",
      "['030_subtomo_[128 824 824]']\n",
      "['037_subtomo_[128 128 360]']\n",
      "['037_subtomo_[128 128 592]']\n",
      "['037_subtomo_[128 360 128]']\n",
      "['037_subtomo_[128 360 360]']\n",
      "['037_subtomo_[128 360 592]']\n",
      "['037_subtomo_[128 592 128]']\n",
      "['037_subtomo_[128 592 360]']\n",
      "['037_subtomo_[128 592 592]']\n",
      "['037_subtomo_[128 592 824]']\n",
      "['037_subtomo_[128 824 128]']\n",
      "['037_subtomo_[128 824 360]']\n",
      "['037_subtomo_[128 824 592]']\n",
      "['037_subtomo_[128 824 824]']\n",
      "['026_subtomo_[128 128 128]']\n",
      "['026_subtomo_[128 128 360]']\n",
      "['026_subtomo_[128 360 128]']\n",
      "['026_subtomo_[128 360 360]']\n",
      "['026_subtomo_[128 592 128]']\n",
      "['026_subtomo_[128 592 360]']\n",
      "['026_subtomo_[128 592 824]']\n",
      "['026_subtomo_[128 824 360]']\n",
      "['026_subtomo_[128 824 592]']\n",
      "['026_subtomo_[128 824 824]']\n",
      "score_0: 0.29258299692004336, std: 0.22136301873407865\n",
      "score_1: 0.29720472705130485, std: 0.22139473251942707\n",
      "score_0_refined: 0.30768873995425655, std: 0.2350805925304408\n",
      "score_1_refined: 0.30491163216385186, std: 0.23617108599209052\n"
     ]
    }
   ],
   "source": [
    "ttt(model, test_loader, 10, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_train_mode(model, test_loader, n_steps, lr):\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "    score_0, score_1 = [], []\n",
    "    score_0_refined, score_1_refined = [], []\n",
    "\n",
    "    for i, batch in enumerate(test_loader):\n",
    "        x, y = torch.Tensor(batch[\"image\"]), torch.Tensor(batch[\"label\"])\n",
    "        print(batch[\"id\"])\n",
    "\n",
    "\n",
    "        y_hat_0 = model.model(x.to(device), y=None)\n",
    "        y_hat_1 = model.model(x.to(device), y=y_hat_0)\n",
    "        \n",
    "        score_0.append((1 - criterion(y_hat_0, y.to(device))).detach().item())\n",
    "        score_1.append((1 - criterion(y_hat_1, y.to(device))).detach().item())\n",
    "\n",
    "    print(f\"score_0: {sum(score_0) / len(score_0)}, std: {np.array(score_0).std()}\")\n",
    "    print(f\"score_1: {sum(score_1) / len(score_1)}, std: {np.array(score_1).std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['034_subtomo_[128 128 360]']\n",
      "['034_subtomo_[128 128 592]']\n",
      "['034_subtomo_[128 128 824]']\n",
      "['034_subtomo_[128 360 128]']\n",
      "['034_subtomo_[128 360 360]']\n",
      "['034_subtomo_[128 360 592]']\n",
      "['034_subtomo_[128 360 824]']\n",
      "['034_subtomo_[128 592 128]']\n",
      "['034_subtomo_[128 592 360]']\n",
      "['034_subtomo_[128 592 592]']\n",
      "['034_subtomo_[128 592 824]']\n",
      "['034_subtomo_[128 824 128]']\n",
      "['034_subtomo_[128 824 360]']\n",
      "['034_subtomo_[128 824 592]']\n",
      "['034_subtomo_[128 824 824]']\n",
      "['030_subtomo_[128 128 592]']\n",
      "['030_subtomo_[128 128 824]']\n",
      "['030_subtomo_[128 360 360]']\n",
      "['030_subtomo_[128 360 592]']\n",
      "['030_subtomo_[128 360 824]']\n",
      "['030_subtomo_[128 592 128]']\n",
      "['030_subtomo_[128 592 360]']\n",
      "['030_subtomo_[128 592 592]']\n",
      "['030_subtomo_[128 592 824]']\n",
      "['030_subtomo_[128 824 128]']\n",
      "['030_subtomo_[128 824 360]']\n",
      "['030_subtomo_[128 824 592]']\n",
      "['030_subtomo_[128 824 824]']\n",
      "['037_subtomo_[128 128 360]']\n",
      "['037_subtomo_[128 128 592]']\n",
      "['037_subtomo_[128 360 128]']\n",
      "['037_subtomo_[128 360 360]']\n",
      "['037_subtomo_[128 360 592]']\n",
      "['037_subtomo_[128 592 128]']\n",
      "['037_subtomo_[128 592 360]']\n",
      "['037_subtomo_[128 592 592]']\n",
      "['037_subtomo_[128 592 824]']\n",
      "['037_subtomo_[128 824 128]']\n",
      "['037_subtomo_[128 824 360]']\n",
      "['037_subtomo_[128 824 592]']\n",
      "['037_subtomo_[128 824 824]']\n",
      "['026_subtomo_[128 128 128]']\n",
      "['026_subtomo_[128 128 360]']\n",
      "['026_subtomo_[128 360 128]']\n",
      "['026_subtomo_[128 360 360]']\n",
      "['026_subtomo_[128 592 128]']\n",
      "['026_subtomo_[128 592 360]']\n",
      "['026_subtomo_[128 592 824]']\n",
      "['026_subtomo_[128 824 360]']\n",
      "['026_subtomo_[128 824 592]']\n",
      "['026_subtomo_[128 824 824]']\n",
      "score_0: 0.3274887332729265, std: 0.21219075475891655\n",
      "score_1: 0.3186177997028126, std: 0.2007041623813865\n"
     ]
    }
   ],
   "source": [
    "inference_train_mode(model, test_loader, 20, 0.0005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
