{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from utils.utils import set_seed\n",
    "from utils.ddw_subtomos import reassemble_subtomos\n",
    "from torchmetrics.classification import BinaryConfusionMatrix, PrecisionRecallCurve\n",
    "import wandb\n",
    "import torchvision.transforms.functional as FT\n",
    "from datasets import build_dataset\n",
    "from models.denoiseg import Denoiseg\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from torch_receptive_field import receptive_field, receptive_field_for_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 2\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg = OmegaConf.merge(cfg, cfg.method)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "criterion = DiceLoss(sigmoid=True)\n",
    "scoring_fn = DiceMetric(reduction='mean')\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss(reduction='none')\n",
    "# mse_loss = nn.L1Loss(reduction='none')\n",
    "device = torch.device(\"cuda:2\")\n",
    "device_1 = torch.device(\"cuda:1\")\n",
    "bcm = BinaryConfusionMatrix().to(device)\n",
    "# pr_curve = PrecisionRecallCurve(task=\"binary\")\n",
    "\n",
    "dataset = build_dataset(cfg, test=True)\n",
    "\n",
    "test_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 2, 2], generator=torch.Generator().manual_seed(cfg.seed))\n",
    "print(len(test_dataset), len(test_val_dataset))\n",
    "# test_dataset = dataset\n",
    "# test_val_dataset = build_dataset(cfg, val=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    # num_workers=cfg.load_num_workers,\n",
    "    num_workers=2,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")            \n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=2,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_entire_gt = mrcfile.read(cfg.test_entire_gt)\n",
    "test_entire_tomo = mrcfile.read(cfg.test_entire_tomo)\n",
    "\n",
    "test_entire_gt = torch.Tensor(test_entire_gt)[None, None, ...]\n",
    "test_entire_tomo = torch.Tensor(test_entire_tomo)\n",
    "\n",
    "test_membrain_pred = mrcfile.read(cfg.test_membrain_pred)\n",
    "test_membrain_pred = torch.Tensor(test_membrain_pred)[None, None, ...]\n",
    "\n",
    "model = Denoiseg.load_from_checkpoint(cfg.ckpt_path, map_location=device, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(x_hat, x, mask):\n",
    "    loss = mse_loss(x_hat, x) * mask\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "def dice_from_conf_matrix(conf_matrix):\n",
    "    return 2 * conf_matrix[1, 1] / (2 * conf_matrix[1, 1] + conf_matrix[0, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def precision_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "\n",
    "def recall_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm\n",
    "\n",
    "def process_id(id):\n",
    "    id = id.split(\"_\")[-1]\n",
    "    id = id[1:-1].split(\" \")\n",
    "    id = [int(elem) for elem in id]\n",
    "    return id\n",
    "\n",
    "def normalize_image(image, max_intensity):\n",
    "\n",
    "    return image * 255.0 / max_intensity\n",
    "\n",
    "def normalize_min_max(image):\n",
    "\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    return image * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_test_loop(test_test_loader, model, run, epoch):\n",
    "    # Test\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = []\n",
    "    ids = []\n",
    "    subtomo_start_coords = []\n",
    "    denoised_preds = []\n",
    "    raws = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(tqdm(test_test_loader)):\n",
    "            x_unmasked = batch[\"raw_subtomo\"].to(device)\n",
    "            # x_unmasked = batch[\"image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            y_hat, x_hat = model.model(x_unmasked)\n",
    "\n",
    "            ## TEST recurrent inference\n",
    "            # y_hat, _ = model.model(x_hat)\n",
    "            ##########################\n",
    "\n",
    "            # dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().item()\n",
    "            conf_matrix += bcm(y_hat.sigmoid(), y_out).detach().cpu()\n",
    "            \n",
    "            # slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "\n",
    "            # id = id[0].replace(\" \", \"_\")\n",
    "            preds.append(y_hat.squeeze().detach().cpu().sigmoid())\n",
    "\n",
    "            denoised_preds.append(x_hat.squeeze().detach().cpu())\n",
    "            # ids.append(process_id(id[0]))\n",
    "            subtomo_start_coords.append(batch[\"start_coord\"][0])\n",
    "            # run.log({\n",
    "            #     f\"train/{i}/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/dice\": dice,\n",
    "            #     # f\"train/{i}/dice_loss\": dice_loss,\n",
    "            #     \"epoch\": epoch,\n",
    "            # })\n",
    "        \n",
    "        # reassembled_pred = reassemble_subtomos(preds, ids, test_entire_gt.shape[2:], 256, 12)\n",
    "        reassembled_pred = reassemble_subtomos(\n",
    "            subtomos=preds,\n",
    "            subtomo_start_coords=subtomo_start_coords,\n",
    "            subtomo_overlap=80,\n",
    "            crop_to_size=test_entire_gt.shape[2:]\n",
    "        )\n",
    "\n",
    "        denoised_reassembled = reassemble_subtomos(\n",
    "            subtomos=denoised_preds,\n",
    "            subtomo_start_coords=subtomo_start_coords,\n",
    "            subtomo_overlap=80,\n",
    "            crop_to_size=test_entire_gt.shape[2:]\n",
    "        )\n",
    "\n",
    "        # reassembled_pred = (torch.Tensor(reassembled_pred).sigmoid() > 0.5).to(torch.uint8)[None, None, ...]\n",
    "        reassembled_pred_binary = (reassembled_pred[None, None, ...] > 0.5).to(torch.uint8)\n",
    "        reassembled_pred_binary_75 = (reassembled_pred[None, None, ...] > 0.75).to(torch.uint8)\n",
    "        reassembled_pred_binary_90 = (reassembled_pred[None, None, ...] > 0.9).to(torch.uint8)\n",
    "        reassembled_pred_binary_98 = (reassembled_pred[None, None, ...] > 0.98).to(torch.uint8)\n",
    "\n",
    "        # postprocessed_pred = torch.Tensor(connected_components(reassembled_pred.squeeze().numpy(), 50)).to(torch.bool).to(torch.uint8)\n",
    "        max_intensity = np.max(test_entire_gt[0].sum(dim=1).numpy())\n",
    "        full_conf_matrix = bcm(reassembled_pred_binary.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_75 = bcm(reassembled_pred_binary_75.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_90 = bcm(reassembled_pred_binary_90.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_98 = bcm(reassembled_pred_binary_98.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "\n",
    "        slice_to_log = torch.argmax(test_entire_gt.squeeze().sum(dim=(-2, -1)))\n",
    "\n",
    "        run.log({\n",
    "            \"train/macro_dice\": dice_from_conf_matrix(conf_matrix),\n",
    "            \"train/rsm_macro_dice\": scoring_fn(reassembled_pred_binary, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/75\": scoring_fn(reassembled_pred_binary_75, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/90\": scoring_fn(reassembled_pred_binary_90, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/98\": scoring_fn(reassembled_pred_binary_98, test_entire_gt).item(),\n",
    "            \"train/rsm_precision\": precision_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_recall\": recall_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_precision/75\": precision_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_recall/75\": recall_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_precision/90\": precision_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_recall/90\": recall_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_precision/98\": precision_from_conf_matrix(full_conf_matrix_98),\n",
    "            \"train/rsm_recall/98\": recall_from_conf_matrix(full_conf_matrix_98),\n",
    "            \"train/denoised\": wandb.Image(denoised_reassembled[slice_to_log]),\n",
    "            \"train/tomo\": wandb.Image(test_entire_tomo[slice_to_log]),\n",
    "\n",
    "            # \"train/rsm_pr_curve\": wandb.plot.pr_curve(\n",
    "            #     test_entire_gt.squeeze().numpy().flatten(),\n",
    "            #     np.stack((1 - reassembled_pred.numpy().flatten(), reassembled_pred.numpy().flatten()), axis=-1),\n",
    "            # ),\n",
    "            \"membrain/macro_dice\": scoring_fn(test_membrain_pred[:, :, :test_entire_gt.shape[2], :test_entire_gt.shape[3], :test_entire_gt.shape[4]], test_entire_gt).item(),\n",
    "            \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(normalize_min_max(test_entire_gt[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/75\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_75[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/90\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_90[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/98\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_98[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/proba\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred.sum(dim=0)), mode=\"L\")),\n",
    "            \"membrain/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(test_membrain_pred[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            # \"train/seg_overall_postprocessed\": wandb.Image(FT.to_pil_image(postprocessed_pred[None, ...].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "def ttt_one_tomo(test_loader, model, n_epochs, lr, momentum, test_val_loader=None, test_test_loader=None):\n",
    "    \n",
    "    random_uuid = uuid.uuid4()\n",
    "    random_string = str(random_uuid).replace(\"-\", \"\")[:5]\n",
    "\n",
    "    run = wandb.init(project=\"cryo-ttt-ttt\", name=f\"{cfg.exp_name}-lr-{lr:.2E}-{random_string}\")\n",
    "    print(cfg)\n",
    "    macro_test_loop(test_test_loader, model, run, epoch=0)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum=momentum, lr=lr)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "        optimizer, \n",
    "        base_lr=0.0003,   # Minimum learning rate\n",
    "        max_lr=0.003,     # Maximum learning rate\n",
    "        step_size_up=5,  # Number of iterations to go from base_lr to max_lr\n",
    "        mode='triangular' # Policy for cyclic variation\n",
    "    )     \n",
    "    \n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        for batch in tqdm(test_loader):\n",
    "            # -------------\n",
    "            # Train step\n",
    "            model.train()\n",
    "\n",
    "            x_masked, x_unmasked = batch[\"image\"].to(device), batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # y_hat, x_hat = model.model(x_masked)\n",
    "            # ### Normalize\n",
    "            # x_masked, mean, std = model.normalize(x_masked)\n",
    "            # ###\n",
    "\n",
    "            y_hat, x_hat = model.model(x_masked)\n",
    "\n",
    "            # ### Denormalize\n",
    "            # x_hat = model.denormalize(x_hat, mean, std)\n",
    "            # ###\n",
    "\n",
    "\n",
    "            loss = masked_mse_loss(x_hat, x_unmasked, mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_grad_norm = get_grad_norm(model.model)\n",
    "            dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().mean().item()\n",
    "\n",
    "            val_losses = []\n",
    "            for batch_val in tqdm(test_val_loader):\n",
    "                # --------------\n",
    "                # Validation step\n",
    "                model.eval()\n",
    "\n",
    "                x_masked_val, x_unmasked_val = batch_val[\"image\"].to(device), batch_val[\"unmasked_image\"].to(device)\n",
    "                y_out_val, id_val = batch_val[\"label\"].to(device), batch_val[\"id\"]\n",
    "                mask_val = batch_val[\"mask\"].to(device)\n",
    "\n",
    "                _, x_hat_val = model.model(x_masked_val)\n",
    "\n",
    "                val_mse_loss = masked_mse_loss(x_hat_val, x_unmasked_val, mask_val)\n",
    "                val_losses.append(val_mse_loss.item())\n",
    "\n",
    "                # slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "            \n",
    "            # Log results after step i\n",
    "            run.log({\n",
    "                \"train/mse_loss\": loss.item(),\n",
    "                \"train/dice_loss\": dice_loss,\n",
    "                \"train/dice\": dice,\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": step,\n",
    "                # \"train/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "                # \"train/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "                # \"train/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/mask\": wandb.Image(FT.to_pil_image((mask[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                \"val/mse_loss\": np.array(val_losses).mean(),\n",
    "                # \"train/grad_norm\": train_grad_norm,\n",
    "                # \"train/intensity_var\": x_hat.var(),\n",
    "                # \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(y_out[0, :].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :] > 0.5).sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            })\n",
    "\n",
    "            step += 1\n",
    "        macro_test_loop(test_test_loader, model, run, epoch=epoch)\n",
    "        \n",
    "    run.finish()\n",
    "    # return y_hat, val_losses, val_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdijor0310\u001b[0m (\u001b[33mcryo-diyor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cryo/cryo-ttt/src/wandb/run-20250315_221654-2brym266</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/2brym266' target=\"_blank\">denoiseg-f2fd-GN-vpp-norm-p160-m5_10-lr-3.00E-03-eede4</a></strong> to <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/2brym266' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/2brym266</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'denoiseg-f2fd-GN-vpp-norm-p160-m5_10', 'wandb_project_name': 'cryo-ttt-v2', 'ckpt_path': '/workspaces/cryo/cryo-ttt/src/ttt_ckpt/denoiseg-f2fd-GN-vpp-norm-p160-m5_10-5ef5f/epoch=197-val/dice_loss=0.65.ckpt', 'seed': 42, 'debug': False, 'devices': [0, 2], 'profiler': None, 'strategy': 'ddp', 'shuffle': False, 'train_load_num_workers': 8, 'val_load_num_workers': 8, 'pin_memory': False, 'persistent_workers': False, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'check_val_every_n_epochs': 1, 'log_every_n_steps': 1, 'num_sanity_val_steps': 0, 'enable_progress_bar': True, 'method': {'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_f2fd', 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'bernoulli_mask_ratio': 0.5, 'phase_inversion_ratio': 0.1, 'min_mask_radius': 0.05, 'max_mask_radius': 0.1, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['vpp/001', 'vpp/002', 'vpp/004'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['vpp/003'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0003_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['def/034'], 'test_entire_tomo': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/tomograms_normalized/TS_034_trimmed.rec', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_034_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/membrain_out_no_aug/TS_034_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}, 'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_f2fd', 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'bernoulli_mask_ratio': 0.5, 'phase_inversion_ratio': 0.1, 'min_mask_radius': 0.05, 'max_mask_radius': 0.1, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['vpp/001', 'vpp/002', 'vpp/004'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['vpp/003'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0003_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['def/034'], 'test_entire_tomo': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/tomograms_normalized/TS_034_trimmed.rec', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_034_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/membrain_out_no_aug/TS_034_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [01:37<00:00,  4.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>membrain/macro_dice</td><td>▁</td></tr><tr><td>train/macro_dice</td><td>▁</td></tr><tr><td>train/rsm_macro_dice</td><td>▁</td></tr><tr><td>train/rsm_macro_dice/75</td><td>▁</td></tr><tr><td>train/rsm_macro_dice/90</td><td>▁</td></tr><tr><td>train/rsm_macro_dice/98</td><td>▁</td></tr><tr><td>train/rsm_precision</td><td>▁</td></tr><tr><td>train/rsm_precision/75</td><td>▁</td></tr><tr><td>train/rsm_precision/90</td><td>▁</td></tr><tr><td>train/rsm_precision/98</td><td>▁</td></tr><tr><td>train/rsm_recall</td><td>▁</td></tr><tr><td>train/rsm_recall/75</td><td>▁</td></tr><tr><td>train/rsm_recall/90</td><td>▁</td></tr><tr><td>train/rsm_recall/98</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>membrain/macro_dice</td><td>0.58896</td></tr><tr><td>train/macro_dice</td><td>0.13253</td></tr><tr><td>train/rsm_macro_dice</td><td>0.12549</td></tr><tr><td>train/rsm_macro_dice/75</td><td>0.05167</td></tr><tr><td>train/rsm_macro_dice/90</td><td>0.0184</td></tr><tr><td>train/rsm_macro_dice/98</td><td>0.00473</td></tr><tr><td>train/rsm_precision</td><td>0.70708</td></tr><tr><td>train/rsm_precision/75</td><td>0.74856</td></tr><tr><td>train/rsm_precision/90</td><td>0.77829</td></tr><tr><td>train/rsm_precision/98</td><td>0.77311</td></tr><tr><td>train/rsm_recall</td><td>0.06886</td></tr><tr><td>train/rsm_recall/75</td><td>0.02676</td></tr><tr><td>train/rsm_recall/90</td><td>0.00931</td></tr><tr><td>train/rsm_recall/98</td><td>0.00237</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denoiseg-f2fd-GN-vpp-norm-p160-m5_10-lr-3.00E-03-eede4</strong> at: <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/2brym266' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/2brym266</a><br> View project at: <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 9 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250315_221654-2brym266/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ttt_one_tomo(test_loader, model,  0, 0.003, 0.9, test_val_loader=test_val_loader, test_test_loader=test_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_inference(test_test_loader, model, num_iter):\n",
    "\n",
    "    random_uuid = uuid.uuid4()\n",
    "    random_string = str(random_uuid).replace(\"-\", \"\")[:5]\n",
    "\n",
    "    run = wandb.init(project=\"cryo-ttt-ttt\", name=f\"{cfg.exp_name}-num-iter-{num_iter}-{random_string}\")\n",
    "\n",
    "    # Test\n",
    "\n",
    "    overall_preds = []\n",
    "    overall_denoised_preds = []\n",
    "    for _ in range(num_iter):\n",
    "        conf_matrix = torch.zeros(2, 2)\n",
    "        preds = []\n",
    "        subtomo_start_coords = []\n",
    "        denoised_preds = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in tqdm(test_test_loader):\n",
    "                x_unmasked = batch[\"image\"].to(device)\n",
    "                y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "                y_hat, x_hat = model.model(x_unmasked)\n",
    "\n",
    "                # dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "                # dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().item()\n",
    "                conf_matrix += bcm(y_hat.sigmoid(), y_out).detach().cpu()\n",
    "                \n",
    "                preds.append(y_hat.squeeze().detach().cpu().sigmoid())\n",
    "\n",
    "                denoised_preds.append(x_hat.squeeze().detach().cpu())\n",
    "                subtomo_start_coords.append(batch[\"start_coord\"][0])\n",
    "            \n",
    "            reassembled_pred = reassemble_subtomos(\n",
    "                subtomos=preds,\n",
    "                subtomo_start_coords=subtomo_start_coords,\n",
    "                subtomo_overlap=80,\n",
    "                crop_to_size=test_entire_gt.shape[2:]\n",
    "            )\n",
    "\n",
    "            denoised_reassembled = reassemble_subtomos(\n",
    "                subtomos=denoised_preds,\n",
    "                subtomo_start_coords=subtomo_start_coords,\n",
    "                subtomo_overlap=80,\n",
    "                crop_to_size=test_entire_gt.shape[2:]\n",
    "            )\n",
    "\n",
    "            reassembled_pred_binary = (reassembled_pred[None, None, ...] > 0.5).to(torch.uint8)\n",
    "            # reassembled_pred_binary_75 = (reassembled_pred[None, None, ...] > 0.75).to(torch.uint8)\n",
    "            # reassembled_pred_binary_90 = (reassembled_pred[None, None, ...] > 0.9).to(torch.uint8)\n",
    "            # reassembled_pred_binary_98 = (reassembled_pred[None, None, ...] > 0.98).to(torch.uint8)\n",
    "\n",
    "            # postprocessed_pred = torch.Tensor(connected_components(reassembled_pred.squeeze().numpy(), 50)).to(torch.bool).to(torch.uint8)\n",
    "            full_conf_matrix = bcm(reassembled_pred_binary.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "            # full_conf_matrix_75 = bcm(reassembled_pred_binary_75.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "            # full_conf_matrix_90 = bcm(reassembled_pred_binary_90.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "            # full_conf_matrix_98 = bcm(reassembled_pred_binary_98.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "\n",
    "            slice_to_log = torch.argmax(test_entire_gt.squeeze().sum(dim=(-2, -1)))\n",
    "\n",
    "            run.log({\n",
    "                \"train/macro_dice\": dice_from_conf_matrix(conf_matrix),\n",
    "                \"train/rsm_macro_dice\": scoring_fn(reassembled_pred_binary, test_entire_gt).item(),\n",
    "                # \"train/rsm_macro_dice/75\": scoring_fn(reassembled_pred_binary_75, test_entire_gt).item(),\n",
    "                # \"train/rsm_macro_dice/90\": scoring_fn(reassembled_pred_binary_90, test_entire_gt).item(),\n",
    "                # \"train/rsm_macro_dice/98\": scoring_fn(reassembled_pred_binary_98, test_entire_gt).item(),\n",
    "                \"train/rsm_precision\": precision_from_conf_matrix(full_conf_matrix),\n",
    "                \"train/rsm_recall\": recall_from_conf_matrix(full_conf_matrix),\n",
    "                # \"train/rsm_precision/75\": precision_from_conf_matrix(full_conf_matrix_75),\n",
    "                # \"train/rsm_recall/75\": recall_from_conf_matrix(full_conf_matrix_75),\n",
    "                # \"train/rsm_precision/90\": precision_from_conf_matrix(full_conf_matrix_90),\n",
    "                # \"train/rsm_recall/90\": recall_from_conf_matrix(full_conf_matrix_90),\n",
    "                # \"train/rsm_precision/98\": precision_from_conf_matrix(full_conf_matrix_98),\n",
    "                # \"train/rsm_recall/98\": recall_from_conf_matrix(full_conf_matrix_98),\n",
    "                \"train/denoised\": wandb.Image(denoised_reassembled[slice_to_log]),\n",
    "                \"train/tomo\": wandb.Image(test_entire_tomo[slice_to_log]),\n",
    "                \"membrain/macro_dice\": scoring_fn(test_membrain_pred[:, :, :test_entire_gt.shape[2], :test_entire_gt.shape[3], :test_entire_gt.shape[4]], test_entire_gt).item(),\n",
    "                \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(normalize_min_max(test_entire_gt[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "                \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall/75\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_75[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall/90\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_90[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall/98\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_98[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "                \"train/seg_overall/proba\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred.sum(dim=0)), mode=\"L\")),\n",
    "                \"membrain/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(test_membrain_pred[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            })\n",
    "\n",
    "        overall_preds.append(reassembled_pred)\n",
    "        overall_denoised_preds.append(denoised_reassembled)\n",
    "\n",
    "    overall_pred = torch.stack(overall_preds, dim=0).max(dim=0)[0]\n",
    "    overall_pred_binary = (overall_pred[None, None, ...] > 0.5).to(torch.uint8)\n",
    "\n",
    "    overall_denoised = torch.stack(overall_denoised_preds, dim=0).mean(dim=0)\n",
    "\n",
    "    run.log({\n",
    "        \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(overall_pred_binary[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "        \"train/rsm_macro_dice\": scoring_fn(overall_pred_binary, test_entire_gt).item(),\n",
    "        \"train/denoised\": wandb.Image(overall_denoised[slice_to_log])\n",
    "    })\n",
    "    \n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdijor0310\u001b[0m (\u001b[33mcryo-diyor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cryo/cryo-ttt/src/wandb/run-20250315_225343-haq4z0pe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/haq4z0pe' target=\"_blank\">denoiseg-f2fd-GN-vpp-norm-p160-m5_10-num-iter-10-784ab</a></strong> to <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/haq4z0pe' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/haq4z0pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [02:13<00:00,  2.97it/s]\n",
      "100%|██████████| 396/396 [00:34<00:00, 11.33it/s]\n",
      "100%|██████████| 396/396 [00:35<00:00, 11.12it/s]\n",
      "100%|██████████| 396/396 [00:35<00:00, 11.20it/s]\n",
      "100%|██████████| 396/396 [00:32<00:00, 12.13it/s]\n",
      "100%|██████████| 396/396 [00:36<00:00, 10.81it/s]\n",
      "100%|██████████| 396/396 [00:37<00:00, 10.60it/s]\n",
      "100%|██████████| 396/396 [00:37<00:00, 10.51it/s]\n",
      "100%|██████████| 396/396 [00:37<00:00, 10.45it/s]\n",
      "100%|██████████| 396/396 [00:38<00:00, 10.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>membrain/macro_dice</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/macro_dice</td><td>▆▃▃▅▅▅█▆▄▁</td></tr><tr><td>train/rsm_macro_dice</td><td>█▆▆▇▇▆█▆▆▄▁</td></tr><tr><td>train/rsm_precision</td><td>▄▁▂▂▃█▂▁▂▃</td></tr><tr><td>train/rsm_recall</td><td>▇▃▄▇▅▄█▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>membrain/macro_dice</td><td>0.58896</td></tr><tr><td>train/macro_dice</td><td>0.11729</td></tr><tr><td>train/rsm_macro_dice</td><td>0.04528</td></tr><tr><td>train/rsm_precision</td><td>0.70642</td></tr><tr><td>train/rsm_recall</td><td>0.04636</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denoiseg-f2fd-GN-vpp-norm-p160-m5_10-num-iter-10-784ab</strong> at: <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/haq4z0pe' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/haq4z0pe</a><br> View project at: <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 62 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250315_225343-haq4z0pe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masked_inference(test_test_loader, model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
