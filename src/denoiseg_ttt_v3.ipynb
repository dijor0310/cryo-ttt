{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from utils.utils import set_seed\n",
    "from utils.ddw_subtomos import reassemble_subtomos\n",
    "from torchmetrics.classification import BinaryConfusionMatrix, PrecisionRecallCurve\n",
    "import wandb\n",
    "import torchvision.transforms.functional as FT\n",
    "from datasets import build_dataset\n",
    "from models.denoiseg import Denoiseg\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from torch_receptive_field import receptive_field, receptive_field_for_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 2\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg = OmegaConf.merge(cfg, cfg.method)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "criterion = DiceLoss(sigmoid=True)\n",
    "scoring_fn = DiceMetric(reduction='mean')\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss(reduction='none')\n",
    "# mse_loss = nn.L1Loss(reduction='none')\n",
    "device = torch.device(\"cuda:2\")\n",
    "device_1 = torch.device(\"cuda:1\")\n",
    "bcm = BinaryConfusionMatrix().to(device)\n",
    "# pr_curve = PrecisionRecallCurve(task=\"binary\")\n",
    "\n",
    "dataset = build_dataset(cfg, test=True)\n",
    "\n",
    "test_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 2, 2], generator=torch.Generator().manual_seed(cfg.seed))\n",
    "print(len(test_dataset), len(test_val_dataset))\n",
    "# test_dataset = dataset\n",
    "# test_val_dataset = build_dataset(cfg, val=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    # num_workers=cfg.load_num_workers,\n",
    "    num_workers=2,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")            \n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=2,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_entire_gt = mrcfile.read(cfg.test_entire_gt)\n",
    "test_entire_tomo = mrcfile.read(cfg.test_entire_tomo)\n",
    "\n",
    "test_entire_gt = torch.Tensor(test_entire_gt)[None, None, ...]\n",
    "test_entire_tomo = torch.Tensor(test_entire_tomo)\n",
    "\n",
    "test_membrain_pred = mrcfile.read(cfg.test_membrain_pred)\n",
    "test_membrain_pred = torch.Tensor(test_membrain_pred)[None, None, ...]\n",
    "\n",
    "model = Denoiseg.load_from_checkpoint(cfg.ckpt_path, map_location=device, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25, 16],\n",
       "        [24, 35]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 100) > 0.5\n",
    "b = torch.rand(1, 100) > 0.5\n",
    "\n",
    "c = bcm(a.to(device), b.to(device)).detach().cpu()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(x_hat, x, mask):\n",
    "    loss = mse_loss(x_hat, x) * mask\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "def dice_from_conf_matrix(conf_matrix):\n",
    "    return 2 * conf_matrix[1, 1] / (2 * conf_matrix[1, 1] + conf_matrix[0, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def precision_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "\n",
    "def recall_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm\n",
    "\n",
    "def process_id(id):\n",
    "    id = id.split(\"_\")[-1]\n",
    "    id = id[1:-1].split(\" \")\n",
    "    id = [int(elem) for elem in id]\n",
    "    return id\n",
    "\n",
    "def normalize_image(image, max_intensity):\n",
    "\n",
    "    return image * 255.0 / max_intensity\n",
    "\n",
    "def normalize_min_max(image):\n",
    "\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    return image * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_test_loop(test_test_loader, model, run, epoch):\n",
    "    # Test\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = []\n",
    "    ids = []\n",
    "    subtomo_start_coords = []\n",
    "    denoised_preds = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(tqdm(test_test_loader)):\n",
    "            x_unmasked = batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            y_hat, x_hat = model.model(x_unmasked)\n",
    "\n",
    "            # dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().item()\n",
    "            conf_matrix += bcm(y_hat.sigmoid(), y_out).detach().cpu()\n",
    "            \n",
    "            # slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "\n",
    "            # id = id[0].replace(\" \", \"_\")\n",
    "            preds.append(y_hat.squeeze().detach().cpu().sigmoid())\n",
    "            denoised_preds.append(x_hat.squeeze().detach().cpu())\n",
    "\n",
    "            # ids.append(process_id(id[0]))\n",
    "            subtomo_start_coords.append(batch[\"start_coord\"][0])\n",
    "            # run.log({\n",
    "            #     f\"train/{i}/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/dice\": dice,\n",
    "            #     # f\"train/{i}/dice_loss\": dice_loss,\n",
    "            #     \"epoch\": epoch,\n",
    "            # })\n",
    "        \n",
    "        # reassembled_pred = reassemble_subtomos(preds, ids, test_entire_gt.shape[2:], 256, 12)\n",
    "        reassembled_pred = reassemble_subtomos(\n",
    "            subtomos=preds,\n",
    "            subtomo_start_coords=subtomo_start_coords,\n",
    "            subtomo_overlap=80,\n",
    "            crop_to_size=test_entire_gt.shape[2:]\n",
    "        )\n",
    "\n",
    "        denoised_reassembled = reassemble_subtomos(\n",
    "            subtomos=denoised_preds,\n",
    "            subtomo_start_coords=subtomo_start_coords,\n",
    "            subtomo_overlap=80,\n",
    "            crop_to_size=test_entire_gt.shape[2:]\n",
    "        )\n",
    "\n",
    "        # reassembled_pred = (torch.Tensor(reassembled_pred).sigmoid() > 0.5).to(torch.uint8)[None, None, ...]\n",
    "        reassembled_pred_binary = (reassembled_pred[None, None, ...] > 0.5).to(torch.uint8)\n",
    "        reassembled_pred_binary_75 = (reassembled_pred[None, None, ...] > 0.75).to(torch.uint8)\n",
    "        reassembled_pred_binary_90 = (reassembled_pred[None, None, ...] > 0.9).to(torch.uint8)\n",
    "        reassembled_pred_binary_98 = (reassembled_pred[None, None, ...] > 0.98).to(torch.uint8)\n",
    "\n",
    "        # postprocessed_pred = torch.Tensor(connected_components(reassembled_pred.squeeze().numpy(), 50)).to(torch.bool).to(torch.uint8)\n",
    "        max_intensity = np.max(test_entire_gt[0].sum(dim=1).numpy())\n",
    "        full_conf_matrix = bcm(reassembled_pred_binary.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_75 = bcm(reassembled_pred_binary_75.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_90 = bcm(reassembled_pred_binary_90.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_98 = bcm(reassembled_pred_binary_98.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "\n",
    "        slice_to_log = torch.argmax(test_entire_gt.squeeze().sum(dim=(-2, -1)))\n",
    "\n",
    "        run.log({\n",
    "            \"train/macro_dice\": dice_from_conf_matrix(conf_matrix),\n",
    "            \"train/rsm_macro_dice\": scoring_fn(reassembled_pred_binary, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/75\": scoring_fn(reassembled_pred_binary_75, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/90\": scoring_fn(reassembled_pred_binary_90, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/98\": scoring_fn(reassembled_pred_binary_98, test_entire_gt).item(),\n",
    "            \"train/rsm_precision\": precision_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_recall\": recall_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_precision/75\": precision_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_recall/75\": recall_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_precision/90\": precision_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_recall/90\": recall_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_precision/98\": precision_from_conf_matrix(full_conf_matrix_98),\n",
    "            \"train/rsm_recall/98\": recall_from_conf_matrix(full_conf_matrix_98),\n",
    "            \"train/denoised\": wandb.Image(denoised_reassembled[slice_to_log]),\n",
    "            \"train/tomo\": wandb.Image(test_entire_tomo[slice_to_log]),\n",
    "            # \"train/rsm_pr_curve\": wandb.plot.pr_curve(\n",
    "            #     test_entire_gt.squeeze().numpy().flatten(),\n",
    "            #     np.stack((1 - reassembled_pred.numpy().flatten(), reassembled_pred.numpy().flatten()), axis=-1),\n",
    "            # ),\n",
    "            \"membrain/macro_dice\": scoring_fn(test_membrain_pred[:, :, :test_entire_gt.shape[2], :test_entire_gt.shape[3], :test_entire_gt.shape[4]], test_entire_gt).item(),\n",
    "            \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(normalize_min_max(test_entire_gt[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/75\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_75[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/90\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_90[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/98\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_98[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"membrain/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(test_membrain_pred[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            # \"train/seg_overall_postprocessed\": wandb.Image(FT.to_pil_image(postprocessed_pred[None, ...].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "def ttt_one_tomo(test_loader, model, n_epochs, lr, momentum, test_val_loader=None, test_test_loader=None):\n",
    "    \n",
    "    random_uuid = uuid.uuid4()\n",
    "    random_string = str(random_uuid).replace(\"-\", \"\")[:5]\n",
    "\n",
    "    run = wandb.init(project=\"cryo-ttt-ttt\", name=f\"{cfg.exp_name}-lr-{lr:.2E}-{random_string}\")\n",
    "    print(cfg)\n",
    "    macro_test_loop(test_test_loader, model, run, epoch=0)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum=momentum, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "        optimizer, \n",
    "        base_lr=0.0003,   # Minimum learning rate\n",
    "        max_lr=0.003,     # Maximum learning rate\n",
    "        step_size_up=5,  # Number of iterations to go from base_lr to max_lr\n",
    "        mode='triangular' # Policy for cyclic variation\n",
    "    )     \n",
    "    \n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        for batch in tqdm(test_loader):\n",
    "            # -------------\n",
    "            # Train step\n",
    "            model.train()\n",
    "\n",
    "            x_masked, x_unmasked = batch[\"image\"].to(device), batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # y_hat, x_hat = model.model(x_masked)\n",
    "            # ### Normalize\n",
    "            # x_masked, mean, std = model.normalize(x_masked)\n",
    "            # ###\n",
    "\n",
    "            y_hat, x_hat = model.model(x_masked)\n",
    "\n",
    "            # ### Denormalize\n",
    "            # x_hat = model.denormalize(x_hat, mean, std)\n",
    "            # ###\n",
    "\n",
    "\n",
    "            loss = masked_mse_loss(x_hat, x_unmasked, mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_grad_norm = get_grad_norm(model.model)\n",
    "            dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().mean().item()\n",
    "\n",
    "            val_losses = []\n",
    "            for batch_val in tqdm(test_val_loader):\n",
    "                # --------------\n",
    "                # Validation step\n",
    "                model.eval()\n",
    "\n",
    "                x_masked_val, x_unmasked_val = batch_val[\"image\"].to(device), batch_val[\"unmasked_image\"].to(device)\n",
    "                y_out_val, id_val = batch_val[\"label\"].to(device), batch_val[\"id\"]\n",
    "                mask_val = batch_val[\"mask\"].to(device)\n",
    "\n",
    "                _, x_hat_val = model.model(x_masked_val)\n",
    "\n",
    "                val_mse_loss = masked_mse_loss(x_hat_val, x_unmasked_val, mask_val)\n",
    "                val_losses.append(val_mse_loss.item())\n",
    "\n",
    "                slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "            \n",
    "            # Log results after step i\n",
    "            run.log({\n",
    "                \"train/mse_loss\": loss.item(),\n",
    "                \"train/dice_loss\": dice_loss,\n",
    "                \"train/dice\": dice,\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": step,\n",
    "                # \"train/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "                # \"train/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "                # \"train/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/mask\": wandb.Image(FT.to_pil_image((mask[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                \"val/mse_loss\": np.array(val_losses).mean(),\n",
    "                # \"train/grad_norm\": train_grad_norm,\n",
    "                # \"train/intensity_var\": x_hat.var(),\n",
    "                # \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(y_out[0, :].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :] > 0.5).sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            })\n",
    "\n",
    "            step += 1\n",
    "        macro_test_loop(test_test_loader, model, run, epoch=epoch)\n",
    "        \n",
    "    run.finish()\n",
    "    # return y_hat, val_losses, val_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdijor0310\u001b[0m (\u001b[33mcryo-diyor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cryo/cryo-ttt/src/wandb/run-20250320_125656-udhvlcxh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/udhvlcxh' target=\"_blank\">n2v-GN-vpp-def-lr-3.00E-03-19b56</a></strong> to <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/udhvlcxh' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/udhvlcxh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'n2v-GN-vpp-def', 'wandb_project_name': 'cryo-ttt-v2', 'ckpt_path': '/workspaces/cryo/cryo-ttt/src/ttt_ckpt/denoiseg-GN-vpp-norm-p160-cb6bb/epoch=157-val/dice_loss=0.52.ckpt', 'seed': 42, 'debug': False, 'devices': [2, 3], 'profiler': None, 'strategy': 'ddp', 'shuffle': False, 'train_load_num_workers': 8, 'val_load_num_workers': 8, 'pin_memory': False, 'persistent_workers': False, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'check_val_every_n_epochs': 1, 'log_every_n_steps': 1, 'num_sanity_val_steps': 0, 'enable_progress_bar': True, 'method': {'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_v2', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['vpp/001', 'vpp/002', 'vpp/004'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['def/034'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_034_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['def/037'], 'test_entire_tomo': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/tomograms_normalized/TS_037_trimmed.rec', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_037_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/membrain_out_no_aug/TS_037_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}, 'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_v2', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['vpp/001', 'vpp/002', 'vpp/004'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['def/034'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_034_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['def/037'], 'test_entire_tomo': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/tomograms_normalized/TS_037_trimmed.rec', 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_037_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/membrain_out_no_aug/TS_037_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:17<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]t]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]t]\n",
      "100%|██████████| 17/17 [01:12<00:00,  4.27s/it]\n",
      "100%|██████████| 264/264 [00:21<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.79s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.85s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]t]\n",
      "100%|██████████| 17/17 [01:30<00:00,  5.33s/it]\n",
      "100%|██████████| 264/264 [00:23<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]]\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]t]\n",
      "100%|██████████| 17/17 [01:04<00:00,  3.81s/it]\n",
      "100%|██████████| 264/264 [00:16<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.56s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.62s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]t]\n",
      "100%|██████████| 17/17 [01:26<00:00,  5.06s/it]\n",
      "100%|██████████| 264/264 [00:22<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.49s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.56s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.56s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]t]\n",
      "100%|██████████| 17/17 [01:26<00:00,  5.09s/it]\n",
      "100%|██████████| 264/264 [00:21<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]t]\n",
      "100%|██████████| 17/17 [01:24<00:00,  4.96s/it]\n",
      "100%|██████████| 264/264 [00:22<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.64s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.72s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]t]\n",
      "100%|██████████| 17/17 [01:29<00:00,  5.26s/it]\n",
      "100%|██████████| 264/264 [00:22<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.92s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.87s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.92s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.92s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]t]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]t]\n",
      "100%|██████████| 17/17 [01:28<00:00,  5.22s/it]\n",
      "100%|██████████| 264/264 [00:16<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.56s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.64s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]t]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]t]\n",
      "100%|██████████| 17/17 [01:25<00:00,  5.05s/it]\n",
      "100%|██████████| 264/264 [00:22<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.49s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]]\n",
      " 47%|████▋     | 8/17 [00:43<00:48,  5.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mttt_one_tomo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_val_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_test_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_test_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 123\u001b[0m, in \u001b[0;36mttt_one_tomo\u001b[0;34m(test_loader, model, n_epochs, lr, momentum, test_val_loader, test_test_loader)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Train step\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     x_masked, x_unmasked \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munmasked_image\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    126\u001b[0m     y_out, \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/module.py:2269\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2266\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(memo, submodule_prefix, remove_duplicate):\n\u001b[1;32m   2267\u001b[0m                 \u001b[38;5;28;01myield\u001b[39;00m m\n\u001b[0;32m-> 2269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, mode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the module in training mode.\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \n\u001b[1;32m   2272\u001b[0m \u001b[38;5;124;03m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f452f52ada0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f452f52aec0, execution_count=6 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7f452f52aa10, raw_cell=\"ttt_one_tomo(test_loader, model, 30, 0.003, 0.9, t..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6469796f722f6372796f222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6469796f722f6372796f2f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2Bzion/workspaces/cryo/cryo-ttt/src/denoiseg_ttt_v3.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:440\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:756\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:362\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:222\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    221\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "ttt_one_tomo(test_loader, model, 30, 0.003, 0.9, test_val_loader=test_val_loader, test_test_loader=test_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
