{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from utils.utils import set_seed\n",
    "from utils.ddw_subtomos import reassemble_subtomos\n",
    "from torchmetrics.classification import BinaryConfusionMatrix, PrecisionRecallCurve\n",
    "import wandb\n",
    "import torchvision.transforms.functional as FT\n",
    "from datasets import build_dataset\n",
    "from models.denoiseg import Denoiseg\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcfile\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from torch_receptive_field import receptive_field, receptive_field_for_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 2\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"configs/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "\n",
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg = OmegaConf.merge(cfg, cfg.method)\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "criterion = DiceLoss(sigmoid=True)\n",
    "scoring_fn = DiceMetric(reduction='mean')\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss(reduction='none')\n",
    "# mse_loss = nn.L1Loss(reduction='none')\n",
    "device = torch.device(\"cuda:0\")\n",
    "device_1 = torch.device(\"cuda:1\")\n",
    "bcm = BinaryConfusionMatrix().to(device)\n",
    "# pr_curve = PrecisionRecallCurve(task=\"binary\")\n",
    "\n",
    "dataset = build_dataset(cfg, test=True)\n",
    "\n",
    "test_dataset, test_val_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 2, 2], generator=torch.Generator().manual_seed(cfg.seed))\n",
    "print(len(test_dataset), len(test_val_dataset))\n",
    "# test_dataset = dataset\n",
    "# test_val_dataset = build_dataset(cfg, val=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    # num_workers=cfg.load_num_workers,\n",
    "    num_workers=2,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")            \n",
    "test_val_loader = torch.utils.data.DataLoader(\n",
    "    test_val_dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=2,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=8,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    # persistent_workers=cfg.persistent_workers,\n",
    ")\n",
    "test_entire_gt = mrcfile.read(cfg.test_entire_gt)\n",
    "test_entire_gt = torch.Tensor(test_entire_gt)[None, None, ...]\n",
    "test_membrain_pred = mrcfile.read(cfg.test_membrain_pred)\n",
    "test_membrain_pred = torch.Tensor(test_membrain_pred)[None, None, ...]\n",
    "\n",
    "model = Denoiseg.load_from_checkpoint(cfg.ckpt_path, map_location=device, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25, 16],\n",
       "        [24, 35]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 100) > 0.5\n",
    "b = torch.rand(1, 100) > 0.5\n",
    "\n",
    "c = bcm(a.to(device), b.to(device)).detach().cpu()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(x_hat, x, mask):\n",
    "    loss = mse_loss(x_hat, x) * mask\n",
    "    return loss.sum() / mask.sum()\n",
    "\n",
    "def dice_from_conf_matrix(conf_matrix):\n",
    "    return 2 * conf_matrix[1, 1] / (2 * conf_matrix[1, 1] + conf_matrix[0, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def precision_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[0, 1])\n",
    "\n",
    "def recall_from_conf_matrix(conf_matrix: torch.Tensor):\n",
    "    return conf_matrix[1, 1] / (conf_matrix[1, 1] + conf_matrix[1, 0])\n",
    "\n",
    "def get_grad_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.data.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm\n",
    "\n",
    "def process_id(id):\n",
    "    id = id.split(\"_\")[-1]\n",
    "    id = id[1:-1].split(\" \")\n",
    "    id = [int(elem) for elem in id]\n",
    "    return id\n",
    "\n",
    "def normalize_image(image, max_intensity):\n",
    "\n",
    "    return image * 255.0 / max_intensity\n",
    "\n",
    "def normalize_min_max(image):\n",
    "\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    return image * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_test_loop(test_test_loader, model, run, epoch):\n",
    "    # Test\n",
    "    conf_matrix = torch.zeros(2, 2)\n",
    "    preds = []\n",
    "    ids = []\n",
    "    subtomo_start_coords = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, batch in enumerate(tqdm(test_test_loader)):\n",
    "            x_unmasked = batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            y_hat, x_hat = model.model(x_unmasked)\n",
    "\n",
    "            # dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().item()\n",
    "            conf_matrix += bcm(y_hat.sigmoid(), y_out).detach().cpu()\n",
    "            \n",
    "            slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "\n",
    "            # id = id[0].replace(\" \", \"_\")\n",
    "            preds.append(y_hat.squeeze().detach().cpu().sigmoid())\n",
    "            # ids.append(process_id(id[0]))\n",
    "            subtomo_start_coords.append(batch[\"start_coord\"][0])\n",
    "            # run.log({\n",
    "            #     f\"train/{i}/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "            #     f\"train/{i}/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "            #     f\"train/{i}/dice\": dice,\n",
    "            #     # f\"train/{i}/dice_loss\": dice_loss,\n",
    "            #     \"epoch\": epoch,\n",
    "            # })\n",
    "        \n",
    "        # reassembled_pred = reassemble_subtomos(preds, ids, test_entire_gt.shape[2:], 256, 12)\n",
    "        reassembled_pred = reassemble_subtomos(\n",
    "            subtomos=preds,\n",
    "            subtomo_start_coords=subtomo_start_coords,\n",
    "            subtomo_overlap=80,\n",
    "            crop_to_size=test_entire_gt.shape[2:]\n",
    "        )\n",
    "        # reassembled_pred = (torch.Tensor(reassembled_pred).sigmoid() > 0.5).to(torch.uint8)[None, None, ...]\n",
    "        reassembled_pred_binary = (reassembled_pred[None, None, ...] > 0.5).to(torch.uint8)\n",
    "        reassembled_pred_binary_75 = (reassembled_pred[None, None, ...] > 0.75).to(torch.uint8)\n",
    "        reassembled_pred_binary_90 = (reassembled_pred[None, None, ...] > 0.9).to(torch.uint8)\n",
    "        reassembled_pred_binary_98 = (reassembled_pred[None, None, ...] > 0.98).to(torch.uint8)\n",
    "\n",
    "        # postprocessed_pred = torch.Tensor(connected_components(reassembled_pred.squeeze().numpy(), 50)).to(torch.bool).to(torch.uint8)\n",
    "        max_intensity = np.max(test_entire_gt[0].sum(dim=1).numpy())\n",
    "        full_conf_matrix = bcm(reassembled_pred_binary.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_75 = bcm(reassembled_pred_binary_75.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_90 = bcm(reassembled_pred_binary_90.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "        full_conf_matrix_98 = bcm(reassembled_pred_binary_98.to(device), test_entire_gt.to(device)).detach().cpu()\n",
    "\n",
    "        run.log({\n",
    "            \"train/macro_dice\": dice_from_conf_matrix(conf_matrix),\n",
    "            \"train/rsm_macro_dice\": scoring_fn(reassembled_pred_binary, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/75\": scoring_fn(reassembled_pred_binary_75, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/90\": scoring_fn(reassembled_pred_binary_90, test_entire_gt).item(),\n",
    "            \"train/rsm_macro_dice/98\": scoring_fn(reassembled_pred_binary_98, test_entire_gt).item(),\n",
    "            \"train/rsm_precision\": precision_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_recall\": recall_from_conf_matrix(full_conf_matrix),\n",
    "            \"train/rsm_precision/75\": precision_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_recall/75\": recall_from_conf_matrix(full_conf_matrix_75),\n",
    "            \"train/rsm_precision/90\": precision_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_recall/90\": recall_from_conf_matrix(full_conf_matrix_90),\n",
    "            \"train/rsm_precision/98\": precision_from_conf_matrix(full_conf_matrix_98),\n",
    "            \"train/rsm_recall/98\": recall_from_conf_matrix(full_conf_matrix_98),\n",
    "\n",
    "            # \"train/rsm_pr_curve\": wandb.plot.pr_curve(\n",
    "            #     test_entire_gt.squeeze().numpy().flatten(),\n",
    "            #     np.stack((1 - reassembled_pred.numpy().flatten(), reassembled_pred.numpy().flatten()), axis=-1),\n",
    "            # ),\n",
    "            \"membrain/macro_dice\": scoring_fn(test_membrain_pred[:, :, :test_entire_gt.shape[2], :test_entire_gt.shape[3], :test_entire_gt.shape[4]], test_entire_gt).item(),\n",
    "            \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(normalize_min_max(test_entire_gt[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/75\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_75[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/90\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_90[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"train/seg_overall/98\": wandb.Image(FT.to_pil_image(normalize_min_max(reassembled_pred_binary_98[0].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            \"membrain/seg_overall\": wandb.Image(FT.to_pil_image(normalize_min_max(test_membrain_pred[0, :].sum(dim=1)).to(torch.uint8), mode=\"L\")),\n",
    "            # \"train/seg_overall_postprocessed\": wandb.Image(FT.to_pil_image(postprocessed_pred[None, ...].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            \"epoch\": epoch,\n",
    "        })\n",
    "\n",
    "def ttt_one_tomo(test_loader, model, n_epochs, lr, momentum, test_val_loader=None, test_test_loader=None):\n",
    "    \n",
    "    random_uuid = uuid.uuid4()\n",
    "    random_string = str(random_uuid).replace(\"-\", \"\")[:5]\n",
    "\n",
    "    run = wandb.init(project=\"cryo-ttt-ttt\", name=f\"{cfg.exp_name}-lr-{lr:.2E}-{random_string}\")\n",
    "    print(cfg)\n",
    "    macro_test_loop(test_test_loader, model, run, epoch=0)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum=momentum, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "        optimizer, \n",
    "        base_lr=0.0003,   # Minimum learning rate\n",
    "        max_lr=0.003,     # Maximum learning rate\n",
    "        step_size_up=5,  # Number of iterations to go from base_lr to max_lr\n",
    "        mode='triangular' # Policy for cyclic variation\n",
    "    )     \n",
    "    \n",
    "    step = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        for batch in tqdm(test_loader):\n",
    "            # -------------\n",
    "            # Train step\n",
    "            model.train()\n",
    "\n",
    "            x_masked, x_unmasked = batch[\"image\"].to(device), batch[\"unmasked_image\"].to(device)\n",
    "            y_out, id = batch[\"label\"].to(device), batch[\"id\"]\n",
    "            mask = batch[\"mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # y_hat, x_hat = model.model(x_masked)\n",
    "            # ### Normalize\n",
    "            # x_masked, mean, std = model.normalize(x_masked)\n",
    "            # ###\n",
    "\n",
    "            y_hat, x_hat = model.model(x_masked)\n",
    "\n",
    "            # ### Denormalize\n",
    "            # x_hat = model.denormalize(x_hat, mean, std)\n",
    "            # ###\n",
    "\n",
    "\n",
    "            loss = masked_mse_loss(x_hat, x_unmasked, mask)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_grad_norm = get_grad_norm(model.model)\n",
    "            dice_loss = criterion(y_hat, y_out).detach().item()\n",
    "            dice = scoring_fn((y_hat.sigmoid() > 0.5).int(), y_out).detach().mean().item()\n",
    "\n",
    "            val_losses = []\n",
    "            for batch_val in tqdm(test_val_loader):\n",
    "                # --------------\n",
    "                # Validation step\n",
    "                model.eval()\n",
    "\n",
    "                x_masked_val, x_unmasked_val = batch_val[\"image\"].to(device), batch_val[\"unmasked_image\"].to(device)\n",
    "                y_out_val, id_val = batch_val[\"label\"].to(device), batch_val[\"id\"]\n",
    "                mask_val = batch_val[\"mask\"].to(device)\n",
    "\n",
    "                _, x_hat_val = model.model(x_masked_val)\n",
    "\n",
    "                val_mse_loss = masked_mse_loss(x_hat_val, x_unmasked_val, mask_val)\n",
    "                val_losses.append(val_mse_loss.item())\n",
    "\n",
    "                slice_to_log = torch.argmax(y_out[0, 0].sum(dim=(-1, -2)))\n",
    "            \n",
    "            # Log results after step i\n",
    "            run.log({\n",
    "                \"train/mse_loss\": loss.item(),\n",
    "                \"train/dice_loss\": dice_loss,\n",
    "                \"train/dice\": dice,\n",
    "                \"epoch\": epoch,\n",
    "                \"step\": step,\n",
    "                # \"train/subtomo\": wandb.Image(x_unmasked[0, :, slice_to_log]),\n",
    "                # \"train/denoised\": wandb.Image(x_hat[0, :, slice_to_log]),\n",
    "                # \"train/seg_gt\": wandb.Image(FT.to_pil_image((y_out[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/mask\": wandb.Image(FT.to_pil_image((mask[0, :, slice_to_log] * 255).to(torch.uint8), mode=\"L\")),\n",
    "                \"val/mse_loss\": np.array(val_losses).mean(),\n",
    "                # \"train/grad_norm\": train_grad_norm,\n",
    "                # \"train/intensity_var\": x_hat.var(),\n",
    "                # \"train/seg_overall_gt\": wandb.Image(FT.to_pil_image(y_out[0, :].sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "                # \"train/seg_overall\": wandb.Image(FT.to_pil_image((y_hat.sigmoid()[0, :] > 0.5).sum(dim=1).to(torch.uint8), mode=\"L\")),\n",
    "            })\n",
    "\n",
    "            step += 1\n",
    "        macro_test_loop(test_test_loader, model, run, epoch=epoch)\n",
    "        \n",
    "    run.finish()\n",
    "    # return y_hat, val_losses, val_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdijor0310\u001b[0m (\u001b[33mcryo-diyor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/cryo/cryo-ttt/src/wandb/run-20250311_150852-a839uldk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/a839uldk' target=\"_blank\">denoseg-f2fd-gn-def-norm-p160-ExpLR-AdamW-bilinear-lr-3.00E-03-83cdb</a></strong> to <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/a839uldk' target=\"_blank\">https://wandb.ai/cryo-diyor/cryo-ttt-ttt/runs/a839uldk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exp_name': 'denoseg-f2fd-gn-def-norm-p160-ExpLR-AdamW-bilinear', 'wandb_project_name': 'cryo-ttt-v2', 'ckpt_path': '/workspaces/cryo/cryo-ttt/src/ttt_ckpt/denoseg-f2fd-gn-def-norm-p160-ExpLR-AdamW-bilinear-186c9/epoch=137-val/dice_loss=0.74.ckpt', 'seed': 42, 'debug': False, 'devices': [0, 1], 'profiler': None, 'strategy': 'ddp', 'shuffle': False, 'train_load_num_workers': 8, 'val_load_num_workers': 8, 'pin_memory': False, 'persistent_workers': False, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'check_val_every_n_epochs': 1, 'log_every_n_steps': 1, 'num_sanity_val_steps': 0, 'enable_progress_bar': True, 'method': {'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_f2fd', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'bernoulli_mask_ratio': 0.5, 'phase_inversion_ratio': 0.1, 'min_mask_radius': 0.1, 'max_mask_radius': 0.2, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['def/026', 'def/030', 'def/034'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['def/037'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_037_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['vpp/001'], 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0001_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/membrain_out_no_aug/TS_0001_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}, 'model_name': 'denoiseg', 'train_batch_size': 32, 'eval_batch_size': 32, 'test_batch_size': 1, 'dataset': 'denoiseg_f2fd', 'mask_ratio': 0.1, 'window_size': 5, 'depth': 2, 'initial_features': 4, 'encoder_dropout': 0.0, 'decoder_dropout': 0.1, 'BN': 'group_norm', 'elu': False, 'bernoulli_mask_ratio': 0.5, 'phase_inversion_ratio': 0.1, 'min_mask_radius': 0.1, 'max_mask_radius': 0.2, 'lambda_ce': 0.2, 'learning_rate': 0.003, 'gamma_decay': 0.99, 'max_epochs': 600, 'train_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'train_tomo_names': ['def/026', 'def/030', 'def/034'], 'val_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'val_tomo_names': ['def/037'], 'val_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/DEF/labels/TS_037_membranes_trimmed.mrc', 'test_data_root_dir': '/media/ssd3/diyor/patch-160-overlap-80', 'test_tomo_names': ['vpp/001'], 'test_entire_gt': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/labels/TS_0001_membranes_trimmed.mrc', 'test_membrain_pred': '/mnt/hdd_pool_zion/userdata/diyor/data/deepict/VPP/membrain_out_no_aug/TS_0001_trimmed_MemBrain_seg_v10_alpha.ckpt_segmented.mrc'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:29<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 47.54 GiB total capacity; 13.70 GiB already allocated; 22.88 MiB free; 14.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mttt_one_tomo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_val_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_test_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_test_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 122\u001b[0m, in \u001b[0;36mttt_one_tomo\u001b[0;34m(test_loader, model, n_epochs, lr, momentum, test_val_loader, test_test_loader)\u001b[0m\n\u001b[1;32m    115\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# y_hat, x_hat = model.model(x_masked)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# ### Normalize\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# x_masked, mean, std = model.normalize(x_masked)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# ###\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m y_hat, x_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_masked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# ### Denormalize\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# x_hat = model.denormalize(x_hat, mean, std)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# ###\u001b[39;00m\n\u001b[1;32m    129\u001b[0m loss \u001b[38;5;241m=\u001b[39m masked_mse_loss(x_hat, x_unmasked, mask)\n",
      "File \u001b[0;32m/opt/conda/envs/ttt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspaces/cryo/cryo-ttt/src/models/denoiseg.py:498\u001b[0m, in \u001b[0;36mUNet3D.forward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m    497\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers[level](x)\n\u001b[0;32m--> 498\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder[level](\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_crop_and_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# apply output conv and activation (if given)\u001b[39;00m\n\u001b[1;32m    501\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_conv(x)\n",
      "File \u001b[0;32m/workspaces/cryo/cryo-ttt/src/models/denoiseg.py:480\u001b[0m, in \u001b[0;36mUNet3D._crop_and_concat\u001b[0;34m(self, from_decoder, from_encoder)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_crop_and_concat\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_decoder, from_encoder):\n\u001b[1;32m    479\u001b[0m     cropped \u001b[38;5;241m=\u001b[39m crop_tensor(from_encoder, from_decoder\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_decoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.95 GiB (GPU 0; 47.54 GiB total capacity; 13.70 GiB already allocated; 22.88 MiB free; 14.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "ttt_one_tomo(test_loader, model, 20, 0.003, 0.9, test_val_loader=test_val_loader, test_test_loader=test_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
